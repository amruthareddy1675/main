# -*- coding: utf-8 -*-
"""Alzheimer_Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rtRSB77OINd9O_nqNPXq7SgZbMFI0HBQ
"""

!pip install pandas scikit-learn matplotlib pillow numpy

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from tqdm import tqdm
from google.colab import files

from google.colab import drive
drive.mount('/content/drive')

csv_path = '/content/alzheimer_dataset.csv'
data = pd.read_csv(csv_path)
print("Data loaded successfully!")
print(data.head())
# Update base path to your Google Drive path
base_path = '/content/drive/MyDrive/Alzheimer_MRI_4_classes_dataset/'

# Fix image paths
data['image_path'] = data['image_path'].apply(lambda x: x.replace('/mnt/data/extracted_data/', base_path))

print("First 5 image paths:")
print(data['image_path'].head())

# Check if the paths exist
for path in data['image_path'].head():
    print(f"Exists: {os.path.exists(path)} | Path: {path}")

base_path = '/content/drive/MyDrive/Alzheimer_MRI_4_classes_dataset/'
data['image_path'] = data['image_path'].apply(lambda x: os.path.join(base_path, x))

missing_files = [path for path in data['image_path'] if not os.path.exists(path)]
if missing_files:
    print(f"Missing files: {len(missing_files)}")
    print(missing_files[:10])  # Show first 10 missing files
else:
    print("All image files are present.")

def preprocess_image(image_path, target_size=(64, 64)):
    img = Image.open(image_path).convert('L')  # Convert to grayscale
    img = img.resize(target_size)  # Resize to target size
    img_array = np.array(img).flatten()  # Flatten to 1D array
    return img_array
X = np.array([preprocess_image(path) for path in tqdm(data['image_path'], desc="Preprocessing Images")])
y = data['label'].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)
print(f"Training samples: {len(X_train)}, Testing samples: {len(X_test)}")

# Step 5: Train Logistic Regression Model
# ===============================
print("Training Logistic Regression model...")
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:\n', conf_matrix)

# Classification Report
report = classification_report(y_test, y_pred)
print('Classification Report:\n', report)

# Plot Confusion Matrix
plt.matshow(conf_matrix, cmap='coolwarm', alpha=0.7)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.colorbar()
plt.show()

def predict_image():
    uploaded = files.upload()
    for filename in uploaded.keys():
        image_path = filename
        img_array = preprocess_image(image_path).reshape(1, -1)
        img_scaled = scaler.transform(img_array)
        prediction = model.predict(img_scaled)
        predicted_label = label_encoder.inverse_transform(prediction)[0]
        print(f'Predicted Label: {predicted_label}')

# Run prediction
predict_image()